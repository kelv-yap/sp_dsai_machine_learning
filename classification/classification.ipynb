{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLIED MACHINE LEARNING ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecturer's Name: Paul <br />\n",
    "Student Name: Yap Li Xen (Kelvin) <br />\n",
    "Student ID: P7414389 <br />\n",
    "Class: DSAI/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    "========\n",
    "<ol>\n",
    "    <li>Background</li>\n",
    "    <li>Exploratory Data Analysis</li>\n",
    "    <li>Data Preparation</li>\n",
    "    <ol>\n",
    "        <li>Data Cleaning</li>\n",
    "        <li>Data Transformation</li>\n",
    "    </ol>\n",
    "    <li>Train Model (Single Model)</li>\n",
    "    <ol>\n",
    "        <li>Select Model</li>\n",
    "        <li>Train Test Split</li>\n",
    "        <li>Train Model</li>\n",
    "        <li>Score Model</li>\n",
    "    </ol>\n",
    "    <li>Evaluate Model (Single Model)</li>\n",
    "    <ol>\n",
    "        <li>confusion_matrix</li>\n",
    "        <li>plot_confusion_matrix</li>\n",
    "        <li>classification_report</li>\n",
    "    </ol>\n",
    "    <li>Model Improvement (Single Model)</li>\n",
    "    <ol>\n",
    "        <li>Hyperparameter Tuning</li>\n",
    "        <li>Bias-variance trade-off</li>\n",
    "    </ol>\n",
    "    <li>Train Model (Multiple Models)</li>\n",
    "    <li>Kaggle Competition</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background\n",
    "==========\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "\n",
    "Complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "======================\n",
    "A first view of the dataset to understand the data structure and data value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/data_description.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, hue=\"Survived\", height=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap=\"YlGnBu\",annot=True,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n",
    "==============\n",
    "* Data Cleaning\n",
    "* Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Selection\n",
    "To remove features that doesn't bring impact or less important to the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SibSp & Parch\n",
    "To normalise the number of sibling/spouse/parents/children aboard the Titanic into single column **hasFamily** with the value 1 (yes) or 0 (no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age     Fare Embarked  hasFamily\n",
      "0         0       3    male  22.0   7.2500        S          1\n",
      "1         1       1  female  38.0  71.2833        C          1\n",
      "2         1       3  female  26.0   7.9250        S          0\n",
      "3         1       1  female  35.0  53.1000        S          1\n",
      "4         0       3    male  35.0   8.0500        S          0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hasFamily'] = np.where((df['SibSp'] <= 0) & (df['Parch'] <= 0), 0, 1)\n",
    "df = df.drop(['SibSp', 'Parch'], 1)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fare\n",
    "To group Fare into multiple folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age Embarked  hasFamily Fare_Group\n",
      "0         0       3    male  22.0        S          1          1\n",
      "1         1       1  female  38.0        C          1          5\n",
      "2         1       3  female  26.0        S          0          1\n",
      "3         1       1  female  35.0        S          1          4\n",
      "4         0       3    male  35.0        S          0          1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare_bins=[0,10,20,40,60,80,100,200,600]\n",
    "fare_labels=[1,2,3,4,5,6,7,8]\n",
    "df['Fare_Group'] = pd.cut(df['Fare'], bins=fare_bins, labels=fare_labels, right=False)\n",
    "df = df.drop('Fare', 1)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Age\n",
    "To normalise Age into 4 categories\n",
    "* Children (0-12)\n",
    "* Adult (13-59)\n",
    "* Elderly (60 and above)\n",
    "* Unknown (No Age Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex Embarked  hasFamily Fare_Group Age_Group\n",
      "0         0       3    male        S          1          1     Adult\n",
      "1         1       1  female        C          1          5     Adult\n",
      "2         1       3  female        S          0          1     Adult\n",
      "3         1       1  female        S          1          4     Adult\n",
      "4         0       3    male        S          0          1     Adult\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'] = df['Age'].fillna(-1)\n",
    "age_bins=[-1,0,13,60,120]\n",
    "age_labels=['Unknown','Children','Adult','Elderly']\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "df = df.drop('Age', 1)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Encoding\n",
    "* column Sex\n",
    "* column Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Embarked  hasFamily Fare_Group Age_Group\n",
      "0         0       3  0.0       0.0          1          1     Adult\n",
      "1         1       1  1.0       1.0          1          5     Adult\n",
      "2         1       3  1.0       0.0          0          1     Adult\n",
      "3         1       1  1.0       0.0          1          4     Adult\n",
      "4         0       3  0.0       0.0          0          1     Adult\n",
      "(889, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "df = df[df['Embarked'].notna()]\n",
    "df['Embarked'] = ohe.fit_transform(df[\"Embarked\"].values.reshape(-1,1)).toarray()\n",
    "df['Sex'] = ohe.fit_transform(df[\"Sex\"].values.reshape(-1,1)).toarray()\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Embarked  hasFamily  Fare_Group_1  Fare_Group_2  \\\n",
      "0         0       3  0.0       0.0          1             1             0   \n",
      "1         1       1  1.0       1.0          1             0             0   \n",
      "2         1       3  1.0       0.0          0             1             0   \n",
      "3         1       1  1.0       0.0          1             0             0   \n",
      "4         0       3  0.0       0.0          0             1             0   \n",
      "\n",
      "   Fare_Group_3  Fare_Group_4  Fare_Group_5  Fare_Group_6  Fare_Group_7  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             0             1             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             1             0             0             0   \n",
      "4             0             0             0             0             0   \n",
      "\n",
      "   Fare_Group_8  Age_Group_Unknown  Age_Group_Children  Age_Group_Adult  \\\n",
      "0             0                  0                   0                1   \n",
      "1             0                  0                   0                1   \n",
      "2             0                  0                   0                1   \n",
      "3             0                  0                   0                1   \n",
      "4             0                  0                   0                1   \n",
      "\n",
      "   Age_Group_Elderly  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(889, 17)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model (Single Model)\n",
    "======================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model\n",
    "Linear SVC is selected as training model following the cheatsheet in our use case\n",
    "\n",
    "![](data/sklearn_cheatsheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Split training and test data into (80/20) and fix random state to 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Survived            889 non-null    int64  \n",
      " 1   Pclass              889 non-null    int64  \n",
      " 2   Sex                 889 non-null    float64\n",
      " 3   Embarked            889 non-null    float64\n",
      " 4   hasFamily           889 non-null    int32  \n",
      " 5   Fare_Group_1        889 non-null    uint8  \n",
      " 6   Fare_Group_2        889 non-null    uint8  \n",
      " 7   Fare_Group_3        889 non-null    uint8  \n",
      " 8   Fare_Group_4        889 non-null    uint8  \n",
      " 9   Fare_Group_5        889 non-null    uint8  \n",
      " 10  Fare_Group_6        889 non-null    uint8  \n",
      " 11  Fare_Group_7        889 non-null    uint8  \n",
      " 12  Fare_Group_8        889 non-null    uint8  \n",
      " 13  Age_Group_Unknown   889 non-null    uint8  \n",
      " 14  Age_Group_Children  889 non-null    uint8  \n",
      " 15  Age_Group_Adult     889 non-null    uint8  \n",
      " 16  Age_Group_Elderly   889 non-null    uint8  \n",
      "dtypes: float64(2), int32(1), int64(2), uint8(12)\n",
      "memory usage: 48.6 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.info()\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model (LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 80.17%\n",
      "Test Data Score: 76.97%\n"
     ]
    }
   ],
   "source": [
    "training_data_score = model.score(X_train, y_train)\n",
    "print(\"Training Data Score: {:.2f}%\".format(training_data_score*100))\n",
    "\n",
    "test_data_score = model.score(X_test, y_test)\n",
    "print(\"Test Data Score: {:.2f}%\".format(test_data_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model\n",
    "============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84 25]\n",
      " [16 53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcy0lEQVR4nO3de7xVdZ3/8dfbw10QONxENEVFDS3JIa9dNM1LNmIzWTqm2Pgbzew2lmVTv7Kafr/m11hpWYGXiS6aaCo6XtAHylhpKAqaooYaAnEAuYqCXM75/P5Y6+gGD3vvJXufvdY57+fjsR57r7XX/q7PRvnw/X7Xd32/igjMzIpsp0YHYGa2o5zIzKzwnMjMrPCcyMys8JzIzKzwnMjMrPCcyLoISe+V9Gyj46gXSb0lzZO0a7r/A0mfanRclg9OZAUkaYGk40qPRcTvI2L/BsXTS9JlkhZLekXSXyX9MP1suqRvd/CdCZKWSuqR7h8q6U5JayStkvSwpE+WfOU84IGIWJrufx/4mqRe9f59ln9OZLZD0kT0VWA8cCgwADgGmJOe8gvgLEna5qtnAb+JiC2SjgDuA/4H2BcYAlwAnFRy/vnAr9p3IqIFeAY4pcY/yQrIiayLkHS0pMUl+wskfUnSE5LWSrpBUp+Szz8saW5aA3pQ0jtLPrtE0vOS1qXNuY+UfHaOpD9K+qGkVcClwLuBWyJiSSQWRMQv06/cCjQD7y0pYzDwYaD9nO8DUyLiPyJiRVrGoxHxsfT8twH7ALO2+dkzgZN36A/OugQnsq7tY8CJwGjgncA5AJIOAa4lqeUMASYBt0nqnX7veZLEMxD4FvBrSSNLyj0MeAEYDnwX+BNwkaRPS3pHae0rIjYAU4Gzt4nrmYh4XFI/4AjgpjK/4x3ACxGxZZvjTwMHV/HnYF2cE1nXdkVaS1oF3A6MS4//CzApImZFRGtETAE2AocDRMSN6ffaIuIGYD5Js7Hdkoj4cURsSRPV/wX+AzgTmA38TdLEkvOnAKdJ6pvun50eAxhM8v9hS5nfMQhY18Hxdeln1s05kXVtS0verwf6p+/3BL6YNivXSFoD7AHsBiDp7JJm5xrgIGBoSVmLSi+SJsMrI+IoksTyXeBaSW9PP/8D8BIwQdLeJE3R69KvrwbagNIa37ZWk/S9bWsAsKbM96ybcCLrnhYB342IQSVbv4i4XtKewFXAZ4AhETEIeBIo7azf7pQpEbEhIq4kST5jSz76JUlN7CzgnohYlp6/HngI+Mcy8T4B7N1+h7PE24HHK/9c6+qcyIqrp6Q+7Ruw7V/ycq4CPiXpMCV2lnSypAHAziSJ6iWAdAjEQeUKk/SF9GZDX0k90mblAN64cwlJIjuOpFk7ZZsivgycI+liSUPSMg+W9FuAiFjMm5u3AO8H7srwu62LciIrrjuBDSXbpdV+MSJmkySUn5DUnJ4jvREQEfOAy0hqSctIOtr/WKHIDel3lgIrgAuBf4yIF0quuQB4kCRR3rZNPA8CH0i3F9K7oZPT39huEkltDoD05sNYkrui1s3JEytaEaR3VOcAx0ZEi6TLgOcj4qcNDs1ywInMzArPTUszKzwnMjMrPCcyMyu8LLfs625oc1PstUfPRodhGcyf39zoECyDDZvWsGnL+m0f4M/khGN2jpWrWqs699EnNk6PiBN35HrVyFUi22uPnjw8fY9Gh2EZnHT86Y0OwTL403PX7HAZK1e18vD0t1V1btPI+UMrn7XjcpXIzCz/AmijrdFhbMWJzMwyCYLNUV3TsrM4kZlZZq6RmVmhBUFrzgbSO5GZWWZt258ApSGcyMwskwBancjMrOhcIzOzQgtgc876yPyIkpllEgStVW6VSPpXSU9JelLS9elEoc2S7pU0P30dXKkcJzIzyyagtcqtHEmjgM8B4yPiIKAJOB24BJgREWOAGel+WU5kZpZJMrK/uq0KPYC+6XoM/YAlwATemA59CnBqpUKcyMwsI9Fa5QYMlTS7ZDuvvZSI+Bvwn8BCkuUA10bEPcCIdCX59hXlh1eKyJ39ZpZJ0tlf9QQaKyJifEcfpH1fE0gWkF4D3CjpE28lJicyM8skGUe2QzMBtTsO+GtEtK/YdTNwJLBM0sh0bYaRwPJKBblpaWaZtYWq2ipYCBwuqZ8kAccCT5OsstW+Uv1EYFqlglwjM7NMalUji4hZkm4CHgO2kKySNRnoD0yVdC5JsjutUllOZGaWSSBaa9SYi4hvAt/c5vBGktpZ1ZzIzCyzKpqNncqJzMwyCcSmaGp0GFtxIjOzTJIBsfm6T+hEZmaZ1Wj4Rc04kZlZJhGiNVwjM7OCa3ONzMyKLOnsz1fqyFc0ZpZ77uw3sy6h1ePIzKzIajmyv1acyMwsszbftTSzIkseGnciM7MCC8RmP6JkZkUWgQfEmlnRyQNizazYAtfIzKwLcGe/mRVaUNV8/J3KiczMMkmWg8tX6shXNGZWAPJ8ZGZWbIFH9ptZF+AamZkVWoRyVyPLVzRmlntJZ39TVVs5kvaXNLdke1nSFyQ1S7pX0vz0dXClmJzIzCyjZM7+arZyIuLZiBgXEeOAvwPWA7cAlwAzImIMMCPdL8uJzMwySTr7VdWWwbHA8xHxIjABmJIenwKcWunL7iMzs8wyjOwfKml2yf7kiJjcwXmnA9en70dERAtARLRIGl7pIk5kZpZJxpH9KyJifLkTJPUCTgG++lZjciIzs8xqvPjIScBjEbEs3V8maWRaGxsJLK9UgPvIzCyTCNjctlNVW5XO4I1mJcBtwMT0/URgWqUCXCMzs0ySpmVt6kCS+gEfBM4vOfw9YKqkc4GFwGmVynEiM7PMajWyPyLWA0O2ObaS5C5m1ZzIauzmycO467pmJBh9wGt88YcL6dUnALjxZ8O4+jujmPrnPzNwSGuDIzWAocPW86WLZzG4eQPRJu66cx+m3bofZ571JCee9AJr1/YGYMq17+CRR3ZrcLT50D78Ik/qmsgknQhcDjQBV0fE9+p5vUZb0dKTW68ZylUzn6F33+Dfz9+TmdMGc/zHV7H8bz2Z88AAho/a1OgwrURrq7hq8sE8/1wzfftu5oor72HOYyMAuPXm/fjdTQc0OMI86kaPKElqAq4kuSMxFjhD0th6XS8vWreIja/tROsW2LhhJ4aM2AzApEtHce7Xl6B8/UPW7a1e1Zfnn2sGYMOGnixauAtDhm5ocFT515bO219p6yz1rJEdCjwXES8ASPotyYjdeXW8ZkMNHbmZj16wnLPePZbefYJD3v8yf3f0Oh6avgtDd93MPge+1ugQrYzhI15ln33X8OwzQxh74Ar+/pT5HHvcAub/pZmrJo/jlVd6NTrEXEjuWuZrObh61g9HAYtK9henx7Yi6TxJsyXNfmllsfuN1q1p4qHpA5kyax7XzXmS19Y3ce+Ng7n+ihGcfXFLo8OzMvr02czXv/FHJv3sXaxf35M7bt+Xfz7nZC684ARWrerDv5w3t9Eh5kb7gNgaP6K0Q+qZyDr6FfGmAxGTI2J8RIwfNiRfWT6rOb/vz657bGLQkFZ69ISjPrSGe25oZunCXlxw3AGcfehYXmrpyYUn7M+q5b7PkhdNTW18/RsPcv99e/LgH3cHYM2aPrS17USEuOuufdjvgJUNjjJfulPTcjGwR8n+7sCSOl6v4YaP2szTj/XjtfWid99g7h8G8J6T1vL9m55//ZyzDx3Lj+961nctcyP4wkUPs2jhAG753f6vHx3cvIHVq/oCcORRi3lxwcBGBZg73e2u5SPAGEmjgb+RPBT6T3W8XsMdcMh63nvyWi48YX+aegT7HrSBkz7hf8nz7MADV3DcB1/kry8M5Cc/mw4kQy3ef8xC9t5nDQQsW7YzV1xe9nHBbidvdy3rlsgiYoukzwDTSYZfXBsRT9Xrenlx9sVLOfvipdv9/JcPd9l7HYX01FPDOOn4j7/puMeMbV+E2NJdEhlARNwJ3FnPa5hZ5+tOTUsz64K6Wx+ZmXVRTmRmVmgZJ1bsFE5kZpZZZ44Rq4YTmZllEgFbqp80sVM4kZlZZm5amlmhuY/MzLqEcCIzs6JzZ7+ZFVqE+8jMrPBEq+9amlnRuY/MzAotj89a5qt+aGb5F0k/WTVbJZIGSbpJ0jOSnpZ0hKRmSfdKmp++Dq5UjhOZmWVWw6muLwfujogDgIOBp4FLgBkRMQaYke6X5aalmWUSNersl7QL8D7gHICI2ARskjQBODo9bQowE/hKubJcIzOzzDI0LYe2r5KWbueVFLM38BLwX5LmSLpa0s7AiIhoSa4TLcDwSvG4RmZmmWW4a7kiIra34EEP4BDgsxExS9LlVNGM7IhrZGaWSVLbUlVbBYuBxRExK92/iSSxLZM0EiB9XV6pICcyM8usFgv0RsRSYJGk9nX4jgXmAbcBE9NjE4FpleJx09LMMqtmaEWVPgv8RlIv4AXgkyQVrKmSzgUWAqdVKsSJzMwyCURbjR5Rioi5QEd9aMdmKceJzMwyq12FrDacyMwsm/CzlmbWFeSsSuZEZmaZFaZGJunHlMm7EfG5ukRkZrkWQFtbQRIZMLvTojCz4gigKDWyiJhSui9p54h4tf4hmVne1XAcWU1UHAySzg80j2R6DSQdLOmndY/MzPIrqtw6STWj2n4EnACsBIiIx0mm3jCzbqm65yw784ZAVXctI2KRtFVQrfUJx8wKIWdNy2oS2SJJRwKRPg/1OdJmppl1QwGRs7uW1TQtPwVcCIwC/gaMS/fNrNtSlVvnqFgji4gVwJmdEIuZFUXOmpbV3LXcW9Ltkl6StFzSNEl7d0ZwZpZTBbxreR0wFRgJ7AbcCFxfz6DMLMfaB8RWs3WSahKZIuJXEbEl3X5N7iqWZtaZarWuZa2Ue9ayOX17v6RLgN+SJLCPA3d0Qmxmllc5u2tZrrP/UZLE1R7x+SWfBfCdegVlZvmmnLXJyj1rObozAzGzgujkjvxqVDWyX9JBwFigT/uxiPhlvYIyszzr3I78alRMZJK+SbJ8+VjgTuAk4A+AE5lZd5WzGlk1dy0/SrKiydKI+CRwMNC7rlGZWb61Vbl1kmqalhsiok3SFkm7kKz66wGxZt1VkSZWLDFb0iDgKpI7ma8AD9czKDPLt1rdtZS0AFhHMqPOlogYnw79ugHYC1gAfCwiVpcrp2LTMiI+HRFrIuLnwAeBiWkT08y6q9o+onRMRIyLiPaFei8BZkTEGGBGul9WuQGxh5T7LCIeqzpMM7PqTSC5wQgwBZgJfKXcF8o1LS8r81kAH8gQWFX+8kQ/TthtXK2LtTr6y6QBjQ7BMnjtu9Xc36ssQ9NyqKTShYwmR8Tkkv0A7pEUwKT0sxER0QIQES2Shle6SLkBscdUHaqZdR9BlkeUVpQ0GTtyVEQsSZPVvZKeeSsh1SY9m1n3UqM+sohYkr4uB24BDgWWSRoJkL4ur1SOE5mZZaaobitbhrSzpAHt74HjgSeB24CJ6WkTgWmV4qnqESUzs63UZvjFCOCWdGGjHsB1EXG3pEeAqZLOBRYCp1UqqJpHlEQy1fXeEfFtSW8Ddo0IjyUz665qkMgi4gWSJ4W2Pb6S5GmiqlXTtPwpcARwRrq/Drgyy0XMrOuotlnZmVP9VNO0PCwiDpE0ByAiVqfLwplZd1WgiRXbbZbURFqZlDSMTn0c1MzyJm8TK1bTtLyC5LbocEnfJZnC5//UNSozy7ecraJUzbqWv5H0KEnnm4BTI8IrjZt1V53c/1WNau5avg1YD9xeeiwiFtYzMDPLsaIlMpIVk9oXIekDjAaeBQ6sY1xmlmPKWS95NU3Ld5Tup7NinL+d083MOl3mkf0R8Zikd9cjGDMriKI1LSVdVLK7E3AI8FLdIjKzfCtiZz9QOuHUFpI+s9/VJxwzK4QiJbJ0IGz/iLi4k+IxsyIoSiKT1CMitpSb8trMuh9RrLuWD5P0h82VdBtwI/Bq+4cRcXOdYzOzPCpoH1kzsJJkjv728WQBOJGZdVcFSmTD0zuWT/JGAmuXs59hZp0qZxmgXCJrAvqzdQJrl7OfYWadqUhNy5aI+HanRWJmxVGgRJavmdPMLB+iWHctM82ZbWbdSFFqZBGxqjMDMbPiKFIfmZlZx5zIzKzQOnka62p4pXEzy0TUdjk4SU2S5kj673S/WdK9kuanr4MrleFEZmaZ1Xhdy88DpeuAXALMiIgxwIx0vywnMjPLrkarKEnaHTgZuLrk8ARgSvp+CnBqpXLcR2Zm2VVf2xoqaXbJ/uSImFyy/yPgy2w97+GIiGgBiIgWScMrXcSJzMyyydZsXBER4zv6QNKHgeUR8aiko3ckJCcyM8uuNnctjwJOkfQhkhXadpH0a2CZpJFpbWwksLxSQe4jM7PM1FbdVk5EfDUido+IvYDTgfsi4hPAbcDE9LSJwLRK8bhGZmaZ1Xlk//eAqZLOBRYCp1X6ghOZmWVThwGxETETmJm+X0nGZ72dyMwsu5yN7HciM7NM2kf254kTmZllprZ8ZTInMjPLJocPjTuRmVlmblqaWfE5kZlZ0blGZmbF50RmZoVWsFWUzMzexOPIzKxriHxlMicyM8vMNbIu7qIfLOSw49axZkUPzv/A/q8fP+WfX+KUT66kbQvMmrEL1/z7bg2M0kqN/rfHaevdROwE7CQWfu1AhkxbTP/H1xCC1gE9WXrOaFoH9Wp0qPnQnQbESroWaJ8B8qB6XSdv7rmhmdv+aygXX77o9WMHH/kKR57wMhccux+bN+3EwCGbGxihdWTRF/enrX/P1/dXHz+SlRN2B2DQfcsYcscSlp+5V4Oiy5+8dfbXc2LFXwAn1rH8XHpyVn/Wrd7634cPn72CG34ynM2bkj/utSt7dvRVy5G2vk2vv9fG1gZGkk+1mFixlupWI4uIByTtVa/yi2TUPhs56LBXOecrS9m0UVz17d34y+P9Gh2Wldj9R38Bwdr3DmPt+5K1Lobcuphd/rSCtr49WHzR/hVK6EYCd/ZvS9J5wHkAfeiaf7mbmqD/wFY+/+F92X/cBr426UUmHn4AyY1sa7SFX347rYN60fTyZna//Fk27dqXDfsNYOWpu7Py1N0ZfNcSBt2/nJWnjGp0qLmRt87+hs/ZHxGTI2J8RIzvSe9Gh1MXK1p68sc7BwLi2bn9aGuDgc1uruRFeyd+6y49eWXcYPoseGWrz9cdOoT+c1Y3IrT8qtG6lrXS8ETWHTx49y6Me0/yl2PU3hvp2StYu6qpwresM2hjK3qt9fX3/eatZeNu/ei57LXXz+n/+Bo27dqnUSHmTvuA2BquNL7DGt607Gou+emLvPOIVxjYvIVfz57Hry4bwfTfNnPRDxYx6b5n2bxZfP/ze+BmZT70eHkzu/38uWSnNVh36BDWHzSQkT9/jl7LXgPB5uZevmNZKqL7TKwo6XrgaJKVhhcD34yIa+p1vbz43qf37PD4//tsx8etsTYP68OL//vNo4NaPrVvA6IpkHzlsbretTyjXmWbWWPlrbPfTUszyyaAnDUt3dlvZtnV4K6lpD6SHpb0uKSnJH0rPd4s6V5J89PXwZXCcSIzs8xqdNdyI/CBiDgYGAecKOlw4BJgRkSMAWak+2U5kZlZZmqLqrZyItE+aK9nugUwAZiSHp8CnFopHicyM8um2mZlkseGSppdsp1XWpSkJklzgeXAvRExCxgRES0A6evwSiG5s9/MMkkGxFbd2b8iIsZv78OIaAXGSRoE3CLpLc2U4xqZmWXXVuVWpYhYA8wkmTFnmaSRAOnr8krfdyIzs8wUUdVWtgxpWFoTQ1Jf4DjgGeA2YGJ62kRgWqV43LQ0s2xq90D4SGCKpCaSStXUiPhvSQ8BUyWdCywETqtUkBOZmWVUm2ctI+IJ4F0dHF8JHJulLCcyM8vOEyuaWaF5gV4z6xJcIzOzwstXHnMiM7Ps1JavtqUTmZllE2Qa7NoZnMjMLBNRebBrZ3MiM7PsnMjMrPCcyMys0NxHZmZdge9amlnBhZuWZlZwgROZmXUB+WpZOpGZWXYeR2ZmxedEZmaFFgGt+WpbOpGZWXaukZlZ4TmRmVmhBVCDOftryYnMzDIKCPeRmVmRBe7sN7MuIGd9ZF5p3Myyi6huK0PSHpLul/S0pKckfT493izpXknz09fBlcJxIjOzjKpMYpVrbVuAL0bE24HDgQsljQUuAWZExBhgRrpflhOZmWUTQFtbdVu5YiJaIuKx9P064GlgFDABmJKeNgU4tVJI7iMzs+yq7yMbKml2yf7kiJi87UmS9gLeBcwCRkRES3KZaJE0vNJFnMjMLKNMjyitiIjx5U6Q1B/4HfCFiHhZUuaInMjMLJuAqNE4Mkk9SZLYbyLi5vTwMkkj09rYSGB5pXLcR2Zm2bVFdVsZSqpe1wBPR8QPSj66DZiYvp8ITKsUjmtkZpZdbcaRHQWcBfxZ0tz02L8B3wOmSjoXWAicVqkgJzIzyyai4h3J6oqJPwDb6xA7NktZTmRmll3ORvY7kZlZRkG0tjY6iK04kZlZNp7Gx8y6BE/jY2ZFFkC4RmZmhRaeWNHMuoC8dfYrcnQbVdJLwIuNjqMOhgIrGh2EZdJV/5vtGRHDdqQASXeT/PlUY0VEnLgj16tGrhJZVyVpdqUHZy1f/N+sWPyspZkVnhOZmRWeE1nneNNEcpZ7/m9WIO4jM7PCc43MzArPiczMCs+JrI4knSjpWUnPSaq4pJU1nqRrJS2X9GSjY7HqOZHViaQm4ErgJGAscEa6Zp/l2y+Aug/gtNpyIqufQ4HnIuKFiNgE/JZkvT7LsYh4AFjV6DgsGyey+hkFLCrZX5weM7MacyKrn47mIvdYF7M6cCKrn8XAHiX7uwNLGhSLWZfmRFY/jwBjJI2W1As4nWS9PjOrMSeyOomILcBngOnA08DUiHiqsVFZJZKuBx4C9pe0OF1b0XLOjyiZWeG5RmZmhedEZmaF50RmZoXnRGZmhedEZmaF50RWIJJaJc2V9KSkGyX124GyfiHpo+n7q8s90C7paElHvoVrLJD0ptV2tnd8m3NeyXitSyV9KWuM1jU4kRXLhogYFxEHAZuAT5V+mM64kVlE/K+ImFfmlKOBzInMrLM4kRXX74F909rS/ZKuA/4sqUnS9yU9IukJSecDKPETSfMk3QEMby9I0kxJ49P3J0p6TNLjkmZI2oskYf5rWht8r6Rhkn6XXuMRSUel3x0i6R5JcyRNouPnTbci6VZJj0p6StJ523x2WRrLDEnD0mP7SLo7/c7vJR1Qkz9NK7aI8FaQDXglfe0BTAMuIKktvQqMTj87D/h6+r43MBsYDfwDcC/QBOwGrAE+mp43ExgPDCOZsaO9rOb09VLgSyVxXAe8J33/NuDp9P0VwDfS9yeTPCQ/tIPfsaD9eMk1+gJPAkPS/QDOTN9/A/hJ+n4GMCZ9fxhwX0cxeuteW4+3lv6sQfpKmpu+/z1wDUmT7+GI+Gt6/Hjgne39X8BAYAzwPuD6iGgFlki6r4PyDwceaC8rIrY3L9dxwFjp9QrXLpIGpNf4h/S7d0haXcVv+pykj6Tv90hjXQm0ATekx38N3Cypf/p7byy5du8qrmFdnBNZsWyIiHGlB9K/0K+WHgI+GxHTtznvQ1SeRkhVnANJl8QREbGhg1iqfuZN0tEkSfGIiFgvaSbQZzunR3rdNdv+GZi5j6zrmQ5cIKkngKT9JO0MPACcnvahjQSO6eC7DwHvlzQ6/W5zenwdMKDkvHtIHognPW9c+vYB4Mz02EnA4AqxDgRWp0nsAJIaYbudgPZa5T8Bf4iIl4G/SjotvYYkHVzhGtYNOJF1PVcD84DH0gU0JpHUvG8B5gN/Bn4G/M+2X4yIl0j62G6W9DhvNO1uBz7S3tkPfA4Yn95MmMcbd0+/BbxP0mMkTdyFFWK9G+gh6QngO8CfSj57FThQ0qPAB4Bvp8fPBM5N43sKTx9uePYLM+sCXCMzs8JzIjOzwnMiM7PCcyIzs8JzIjOzwnMiM7PCcyIzs8L7/1UCRC6gk70AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test)\n",
    "plt.title(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       109\n",
      "           1       0.68      0.77      0.72        69\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.76      0.77      0.76       178\n",
      "weighted avg       0.78      0.77      0.77       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Improvement (Single Model)\n",
    "=============================\n",
    "* Hyperparameter Tuning\n",
    "* Bias-variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hyperparameter Tuning\n",
    "To use GridSearchCV which includes Cross Validation to identify best paramter and best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.790, test=0.762), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.775, test=0.824), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.779, test=0.810), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.782, test=0.746), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.789, test=0.725), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.812, test=0.790), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.800, test=0.838), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.777, test=0.796), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.805, test=0.803), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.801, test=0.732), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.801, test=0.776), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.796, test=0.831), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.772, test=0.810), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.810, test=0.789), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.807, test=0.768), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.801, test=0.776), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.794, test=0.831), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.784, test=0.803), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.810, test=0.789), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.801, test=0.761), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.724, test=0.706), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.786, test=0.803), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.399, test=0.401), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.789, test=0.739), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.772, test=0.746), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm = LinearSVC()\n",
    "param_grid = {'C': [0.01,0.1,1.0,10.0,100.0]}\n",
    "grid_search = GridSearchCV(svm, param_grid=param_grid, cv=5, verbose=3, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param: {'C': 1.0}\n",
      "Best Score: 79.47%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Param: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.2f}%\".format(grid_search.best_score_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bias-variance trade-off\n",
    "To identify Appropriate-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "validation_score = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_score = grid_search.cv_results_[\"mean_train_score\"]\n",
    "plt.plot(validation_score, label=\"validation\")\n",
    "plt.plot(train_score, label=\"training\")\n",
    "plt.xticks(np.arange(5), param_grid['C']); plt.xlabel(\"C\"); plt.ylabel(\"Accuracy\");plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model (Multiple Models)\n",
    "=========================\n",
    "To train multiple models and compare the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign multiple models & their corresponding param_grid into Dictionary Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Dict = [\n",
    "    {'model': LogisticRegression(),\n",
    "     'param_grid': {'C': [0.01,0.1,1.0,10.0,100.0], 'penalty': ['l1', 'l2', 'elasticnet', 'none']}},\n",
    "    {'model': KNeighborsClassifier(),\n",
    "     'param_grid': {'n_neighbors': [1,2,3,4,5,6,7,8,9]}},\n",
    "    {'model': GaussianNB(),\n",
    "     'param_grid': {'var_smoothing': np.logspace(0,-9, num=100)}},\n",
    "    {'model': DecisionTreeClassifier(),\n",
    "     'param_grid': {'criterion': ['gini', 'entropy']}},\n",
    "    {'model': SVC(),\n",
    "     'param_grid': {'C': [0.01,0.1,1.0,10.0,100.0]}},\n",
    "    {'model': LinearSVC(),\n",
    "     'param_grid': {'C': [0.01,0.1,1.0,10.0,100.0], 'penalty': ['l1', 'l2']}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Dictionary and compile all scores into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.769, test=0.727), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.752, test=0.782), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.749, test=0.789), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.763, test=0.739), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.761, test=0.761), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.791, test=0.810), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.801, test=0.789), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.794, test=0.768), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.798, test=0.762), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.780, test=0.824), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.789, test=0.796), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.789, test=0.775), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.798, test=0.761), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.791, test=0.810), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.801, test=0.789), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.794, test=0.768), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.791, test=0.831), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.784, test=0.803), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.800, test=0.796), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.803, test=0.775), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.791, test=0.810), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.801, test=0.789), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.794, test=0.768), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.789, test=0.810), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.803, test=0.796), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.803, test=0.775), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.791, test=0.810), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.801, test=0.789), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.794, test=0.768), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.791, test=0.810), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100.0, penalty=l2, score=(train=0.801, test=0.789), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.794, test=0.768), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.803, test=0.762), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.786, test=0.824), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.791, test=0.810), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.801, test=0.789), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.794, test=0.768), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.857, test=0.797), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.814, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.828, test=0.831), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.845, test=0.775), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.715, test=0.669), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.859, test=0.790), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.828, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.822, test=0.810), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.814, test=0.739), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.815, test=0.746), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.854, test=0.790), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.817, test=0.796), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.812, test=0.824), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.845, test=0.768), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.835, test=0.725), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.838, test=0.783), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.821, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.817, test=0.852), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.833, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.833, test=0.746), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.833, test=0.776), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.817, test=0.768), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.812, test=0.831), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.849, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.830, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.835, test=0.783), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.815, test=0.796), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.808, test=0.845), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.838, test=0.782), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.833, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.826, test=0.790), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.814, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.815, test=0.803), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.824, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.828, test=0.746), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.820, test=0.783), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.819, test=0.768), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.817, test=0.845), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.819, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.821, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.815, test=0.804), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.822, test=0.782), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.812, test=0.796), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.822, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.822, test=0.761), total=   0.0s\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.736, test=0.699), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.721, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.710, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.731, test=0.690), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.756, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.771, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.756, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.724, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.761, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.761, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.769, test=0.741), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.766, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.759, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.766, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.759, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.761, test=0.734), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.768, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.759, test=0.796), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.764, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.763, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.764, test=0.734), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.782, test=0.782), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.756, test=0.810), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.763, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.754, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.773, test=0.748), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.777, test=0.775), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.766, test=0.838), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.780, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.777, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.775, test=0.748), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.779, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.766, test=0.810), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.779, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.777, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.773, test=0.741), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.773, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.764, test=0.810), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.773, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.768, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.771, test=0.734), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.763, test=0.782), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.752, test=0.817), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.766, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.768, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.769, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.761, test=0.782), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.743, test=0.810), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.756, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.764, test=0.704), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.754, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.756, test=0.782), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.742, test=0.803), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.745, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.764, test=0.704), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.759, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.761, test=0.782), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.738, test=0.803), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.747, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.763, test=0.697), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.757, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.763, test=0.782), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.736, test=0.803), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.761, test=0.697), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.757, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.752, test=0.775), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.736, test=0.810), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.752, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.764, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.755, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.750, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.736, test=0.803), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.750, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.761, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.764, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.743, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.735, test=0.796), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.750, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.759, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.764, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.749, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.738, test=0.796), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.750, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.759, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.769, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.749, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.742, test=0.803), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.759, test=0.775), total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.759, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.769, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.745, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.742, test=0.803), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.745, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.757, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.769, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.743, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.759, test=0.796), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.754, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.736, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.773, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.743, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.759, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.733, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.740, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.759, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.750, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.759, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.735, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.740, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.738, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.750, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.735, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.740, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.738, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.750, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.735, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.740, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.738, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.750, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.735, test=0.718), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.740, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.739, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.754, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.740, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.739, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.740, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.739, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.740, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.739, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.761, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.740, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.739, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.738, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.739, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.738, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.736, test=0.692), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.738, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.738, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.736, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=0.0001, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=1e-09, score=(train=0.713, test=0.671), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.731, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.735, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.733, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.742, test=0.739), total=   0.0s\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.873, test=0.811), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.866, test=0.845), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.866, test=0.817), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.873, test=0.754), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.870, test=0.824), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.873, test=0.797), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.866, test=0.845), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.866, test=0.817), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.873, test=0.782), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.870, test=0.824), total=   0.0s\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.620, test=0.615), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.619, test=0.620), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.619, test=0.620), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.619, test=0.620), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.619, test=0.620), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.790, test=0.776), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.794, test=0.775), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.796, test=0.789), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.791, test=0.789), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.800, test=0.768), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.831, test=0.832), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.822, test=0.803), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.824, test=0.810), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.837, test=0.789), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.828, test=0.831), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.856, test=0.818), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.849, test=0.803), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.851, test=0.810), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.858, test=0.810), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.858, test=0.796), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.870, test=0.797), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.865, test=0.831), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.863, test=0.782), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.870, test=0.775), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.868, test=0.803), total=   0.0s\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.790, test=0.762), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.775, test=0.824), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.779, test=0.810), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.782, test=0.746), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.789, test=0.725), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.812, test=0.790), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.800, test=0.838), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.777, test=0.796), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.805, test=0.803), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.801, test=0.732), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.801, test=0.776), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.796, test=0.831), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.772, test=0.810), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.810, test=0.789), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.807, test=0.768), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.798, test=0.776), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.796, test=0.831), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.787, test=0.789), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.810, test=0.789), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.801, test=0.761), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.789, test=0.769), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.434, test=0.408), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.786, test=0.803), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.807, test=0.775), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.794, test=0.746), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i in Dict:\n",
    "    # Fit Training Data to model selected\n",
    "    model = i['model']\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict Train Data\n",
    "    y_predict_train_data = model.predict(X_train)\n",
    "    x_train_accuracy_score = accuracy_score(y_train, y_predict_train_data)\n",
    "    x_train_auc_score = roc_auc_score(y_train, y_predict_train_data)\n",
    "\n",
    "    # Predict Test Data\n",
    "    y_predict_test_data = model.predict(X_test)\n",
    "    x_test_accuracy_score = accuracy_score(y_test, y_predict_test_data)\n",
    "    x_test_auc_score = roc_auc_score(y_test, y_predict_test_data)\n",
    "\n",
    "    # Calculate Confusion_Matrix\n",
    "    cm = confusion_matrix(y_test, y_predict_test_data)\n",
    "\n",
    "    # Perform Hyperparameter Tuning & Cross Validation\n",
    "    grid_search = GridSearchCV(model, param_grid=i['param_grid'], cv=5, verbose=3, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    rows.append([model, \n",
    "                 \"{:.2f}%\".format(x_train_accuracy_score*100), \n",
    "                 \"{:.2f}%\".format(x_test_accuracy_score*100), \n",
    "                 \"{:.2f}\".format(x_train_auc_score), \n",
    "                 \"{:.2f}\".format(x_test_auc_score), \n",
    "                 cm,\n",
    "                 grid_search.best_params_,\n",
    "                 \"{:.2f}%\".format(grid_search.best_score_*100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Summary Table Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Algorithm accuracy_score(train) accuracy_score(test)  \\\n",
      "0      LogisticRegression()                79.89%               75.84%   \n",
      "1    KNeighborsClassifier()                83.12%               79.78%   \n",
      "2              GaussianNB()                73.42%               73.60%   \n",
      "3  DecisionTreeClassifier()                86.64%               79.78%   \n",
      "4                     SVC()                82.56%               82.58%   \n",
      "5               LinearSVC()                80.17%               76.97%   \n",
      "\n",
      "  roc_auc_score(train) roc_auc_score(test)      Confusion Matrix  \\\n",
      "0                 0.78                0.76  [[82, 27], [16, 53]]   \n",
      "1                 0.81                0.78  [[92, 17], [19, 50]]   \n",
      "2                 0.70                0.71  [[91, 18], [29, 40]]   \n",
      "3                 0.85                0.79  [[90, 19], [17, 52]]   \n",
      "4                 0.80                0.82  [[92, 17], [14, 55]]   \n",
      "5                 0.78                0.77  [[84, 25], [16, 53]]   \n",
      "\n",
      "                              Best Param Best Score  \n",
      "0            {'C': 1.0, 'penalty': 'l2'}     79.33%  \n",
      "1                     {'n_neighbors': 6}     79.33%  \n",
      "2  {'var_smoothing': 0.3511191734215131}     77.08%  \n",
      "3               {'criterion': 'entropy'}     81.30%  \n",
      "4                             {'C': 1.0}     81.29%  \n",
      "5            {'C': 1.0, 'penalty': 'l2'}     79.47%  \n"
     ]
    }
   ],
   "source": [
    "summary_table = pd.DataFrame(rows, columns=[\"Algorithm\", \n",
    "                                            \"accuracy_score(train)\", \n",
    "                                            \"accuracy_score(test)\", \n",
    "                                            \"roc_auc_score(train)\", \n",
    "                                            \"roc_auc_score(test)\", \n",
    "                                            \"Confusion Matrix\",\n",
    "                                            \"Best Param\",\n",
    "                                            \"Best Score\"])\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Competition\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "df.info()\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_score = model.score(X_train, y_train)\n",
    "print(\"Training Data Score: {:.2f}%\".format(training_data_score*100))\n",
    "\n",
    "test_data_score = model.score(X_test, y_test)\n",
    "print(\"Test Data Score: {:.2f}%\".format(test_data_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References / Appendixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://www.kaggle.com/c/titanic/data\n",
    "2. https://scikit-learn.org/stable/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
