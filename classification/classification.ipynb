{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLIED MACHINE LEARNING ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecturer's Name: Paul <br />\n",
    "Student Name: Yap Li Xen (Kelvin) <br />\n",
    "Student ID: P7414389 <br />\n",
    "Class: DSAI/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background\n",
    "==========\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "\n",
    "Complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "======================\n",
    "A first view of the dataset to understand the data structure and data value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Imported Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image\\data_description.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List DataFrame Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List DataFrame Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of missing value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, hue=\"Survived\", height=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap=\"YlGnBu\",annot=True,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "To remove features that doesn't bring impact or less important to the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['PassengerId', 'Name', 'Ticket'], 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp & Parch\n",
    "To normalise the number of sibling/spouse/parents/children aboard the Titanic into single column **hasFamilyAboard** with the value \"Yes\" or \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age     Fare Cabin Embarked hasFamilyAboard\n",
      "0         0       3    male  22.0   7.2500   NaN        S              No\n",
      "1         1       1  female  38.0  71.2833   C85        C              No\n",
      "2         1       3  female  26.0   7.9250   NaN        S              No\n",
      "3         1       1  female  35.0  53.1000  C123        S              No\n",
      "4         0       3    male  35.0   8.0500   NaN        S              No\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hasFamilyAboard'] = np.where((df['SibSp'] > 0) & (df['Parch'] > 0), 'Yes', 'No')\n",
    "df = df.drop(['SibSp', 'Parch'], 1)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare\n",
    "To group Fare into multiple folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age Cabin Embarked hasFamilyAboard Fare_Group\n",
      "0         0       3    male  22.0   NaN        S              No          1\n",
      "1         1       1  female  38.0   C85        C              No          5\n",
      "2         1       3  female  26.0   NaN        S              No          1\n",
      "3         1       1  female  35.0  C123        S              No          4\n",
      "4         0       3    male  35.0   NaN        S              No          1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare_bins=[0,10,20,40,60,80,100,200,600]\n",
    "fare_labels=[1,2,3,4,5,6,7,8]\n",
    "df['Fare_Group'] = pd.cut(df['Fare'], bins=fare_bins, labels=fare_labels, right=False)\n",
    "df = df.drop('Fare', 1)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin\n",
    "There are many missing data in this column. Transform into \"Yes\" (with records) and \"No\" (without record) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age Cabin Embarked hasFamilyAboard Fare_Group\n",
      "0         0       3    male  22.0    No        S              No          1\n",
      "1         1       1  female  38.0   Yes        C              No          5\n",
      "2         1       3  female  26.0    No        S              No          1\n",
      "3         1       1  female  35.0   Yes        S              No          4\n",
      "4         0       3    male  35.0    No        S              No          1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin'].fillna('No', inplace=True)\n",
    "df['Cabin'].replace(regex=r'^((?!No).)*$',value='Yes',inplace=True)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "* To replace missing value (NaN) with mean value of Age\n",
    "* To normalise Age into 3 categories\n",
    "    * Children (0-12)\n",
    "    * Adult (13-59)\n",
    "    * Elderly (60 and above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex Cabin Embarked hasFamilyAboard Fare_Group  \\\n",
      "0         0       3    male    No        S              No          1   \n",
      "1         1       1  female   Yes        C              No          5   \n",
      "2         1       3  female    No        S              No          1   \n",
      "3         1       1  female   Yes        S              No          4   \n",
      "4         0       3    male    No        S              No          1   \n",
      "\n",
      "  Age_Group  \n",
      "0     Adult  \n",
      "1     Adult  \n",
      "2     Adult  \n",
      "3     Adult  \n",
      "4     Adult  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "age_bins=[0,13,60,120]\n",
    "age_labels=['Children','Adult','Elderly']\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "df = df.drop('Age', 1)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked\n",
    "To replace missing value (NaN) with mode value of Embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex Cabin Embarked hasFamilyAboard Fare_Group  \\\n",
      "0         0       3    male    No        S              No          1   \n",
      "1         1       1  female   Yes        C              No          5   \n",
      "2         1       3  female    No        S              No          1   \n",
      "3         1       1  female   Yes        S              No          4   \n",
      "4         0       3    male    No        S              No          1   \n",
      "\n",
      "  Age_Group  \n",
      "0     Adult  \n",
      "1     Adult  \n",
      "2     Adult  \n",
      "3     Adult  \n",
      "4     Adult  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "Encode all categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex_female  Sex_male  Cabin_No  Cabin_Yes  Embarked_C  \\\n",
      "0         0       3           0         1         1          0           0   \n",
      "1         1       1           1         0         0          1           1   \n",
      "2         1       3           1         0         1          0           0   \n",
      "3         1       1           1         0         0          1           0   \n",
      "4         0       3           0         1         1          0           0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  hasFamilyAboard_No  ...  Fare_Group_2  \\\n",
      "0           0           1                   1  ...             0   \n",
      "1           0           0                   1  ...             0   \n",
      "2           0           1                   1  ...             0   \n",
      "3           0           1                   1  ...             0   \n",
      "4           0           1                   1  ...             0   \n",
      "\n",
      "   Fare_Group_3  Fare_Group_4  Fare_Group_5  Fare_Group_6  Fare_Group_7  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             0             1             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             1             0             0             0   \n",
      "4             0             0             0             0             0   \n",
      "\n",
      "   Fare_Group_8  Age_Group_Children  Age_Group_Adult  Age_Group_Elderly  \n",
      "0             0                   0                1                  0  \n",
      "1             0                   0                1                  0  \n",
      "2             0                   0                1                  0  \n",
      "3             0                   0                1                  0  \n",
      "4             0                   0                1                  0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 22)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the most important features relative to Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived               1.000000\n",
      "Sex_female             0.543351\n",
      "Cabin_Yes              0.316912\n",
      "Embarked_C             0.168240\n",
      "Fare_Group_6           0.162583\n",
      "Fare_Group_7           0.150716\n",
      "Age_Group_Children     0.116691\n",
      "Fare_Group_4           0.099358\n",
      "Fare_Group_8           0.098513\n",
      "Fare_Group_5           0.055730\n",
      "Fare_Group_3           0.051066\n",
      "hasFamilyAboard_Yes    0.047257\n",
      "Fare_Group_2           0.042006\n",
      "Embarked_Q             0.003650\n",
      "Age_Group_Elderly     -0.040857\n",
      "hasFamilyAboard_No    -0.047257\n",
      "Age_Group_Adult       -0.078779\n",
      "Embarked_S            -0.149683\n",
      "Fare_Group_1          -0.295081\n",
      "Cabin_No              -0.316912\n",
      "Pclass                -0.338481\n",
      "Sex_male              -0.543351\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "corr.sort_values([\"Survived\"], ascending = False, inplace = True)\n",
    "print(corr[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model (Single Model)\n",
    "======================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model\n",
    "Linear SVC is selected as training model following the cheat-sheet in our use case\n",
    "\n",
    "![](image\\sklearn_cheatsheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Split training and test data into (80/20) and fix random state to 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 22 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   Survived             891 non-null    int64\n",
      " 1   Pclass               891 non-null    int64\n",
      " 2   Sex_female           891 non-null    uint8\n",
      " 3   Sex_male             891 non-null    uint8\n",
      " 4   Cabin_No             891 non-null    uint8\n",
      " 5   Cabin_Yes            891 non-null    uint8\n",
      " 6   Embarked_C           891 non-null    uint8\n",
      " 7   Embarked_Q           891 non-null    uint8\n",
      " 8   Embarked_S           891 non-null    uint8\n",
      " 9   hasFamilyAboard_No   891 non-null    uint8\n",
      " 10  hasFamilyAboard_Yes  891 non-null    uint8\n",
      " 11  Fare_Group_1         891 non-null    uint8\n",
      " 12  Fare_Group_2         891 non-null    uint8\n",
      " 13  Fare_Group_3         891 non-null    uint8\n",
      " 14  Fare_Group_4         891 non-null    uint8\n",
      " 15  Fare_Group_5         891 non-null    uint8\n",
      " 16  Fare_Group_6         891 non-null    uint8\n",
      " 17  Fare_Group_7         891 non-null    uint8\n",
      " 18  Fare_Group_8         891 non-null    uint8\n",
      " 19  Age_Group_Children   891 non-null    uint8\n",
      " 20  Age_Group_Adult      891 non-null    uint8\n",
      " 21  Age_Group_Elderly    891 non-null    uint8\n",
      "dtypes: int64(2), uint8(20)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.info()\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model (LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 80.76%\n",
      "Test Data Score: 79.89%\n"
     ]
    }
   ],
   "source": [
    "training_data_score = model.score(X_train, y_train)\n",
    "print(\"Training Data Score: {:.2f}%\".format(training_data_score*100))\n",
    "\n",
    "test_data_score = model.score(X_test, y_test)\n",
    "print(\"Test Data Score: {:.2f}%\".format(test_data_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model (Single Model)\n",
    "========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 15]\n",
      " [21 53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test)\n",
    "plt.title(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       105\n",
      "           1       0.78      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Improvement (Single Model)\n",
    "============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hyperparameter Tuning\n",
    "To use GridSearchCV which includes Cross Validation to identify best paramter and best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.801, test=0.804), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.794, test=0.797), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.798, test=0.754), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.811, test=0.761), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.795, test=0.831), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.803, test=0.811), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.800, test=0.804), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.804, test=0.746), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.818, test=0.739), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.798, test=0.817), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.803, test=0.811), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.791, test=0.811), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.802, test=0.754), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.818, test=0.732), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.789, test=0.796), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.803, test=0.811), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.791, test=0.811), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.805, test=0.775), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.819, test=0.732), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.791, test=0.796), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.814, test=0.804), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.807, test=0.818), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.804, test=0.789), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.818, test=0.732), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.802, test=0.817), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.4s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm = LinearSVC()\n",
    "param_grid = {'C': [0.01,0.1,1.0,10.0,100.0]}\n",
    "grid_search = GridSearchCV(svm, param_grid=param_grid, cv=5, verbose=3, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param: {'C': 100.0}\n",
      "Best Score: 79.21%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Param: {}\".format(grid_search.best_params_))\n",
    "print(\"Best Score: {:.2f}%\".format(grid_search.best_score_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bias-variance trade-off\n",
    "To identify Appropriate-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "validation_score = grid_search.cv_results_[\"mean_test_score\"]\n",
    "train_score = grid_search.cv_results_[\"mean_train_score\"]\n",
    "plt.plot(validation_score, label=\"validation\")\n",
    "plt.plot(train_score, label=\"training\")\n",
    "plt.xticks(np.arange(5), param_grid['C']); plt.xlabel(\"C\"); plt.ylabel(\"Accuracy\");plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model (Multiple Models)\n",
    "=========================\n",
    "To train multiple models and compare the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign multiple models & their corresponding param_grid into Dictionary Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Dict = [\n",
    "    {'model': LogisticRegression(),\n",
    "     'param_grid': {'C': [0.01,0.1,1.0,10.0,100.0], 'penalty': ['l1', 'l2', 'elasticnet', 'none']}},\n",
    "    {'model': KNeighborsClassifier(),\n",
    "     'param_grid': {'n_neighbors': [1,2,3,4,5,6,7,8,9]}},\n",
    "    {'model': GaussianNB(),\n",
    "     'param_grid': {'var_smoothing': np.logspace(0,-9, num=100)}},\n",
    "    {'model': DecisionTreeClassifier(),\n",
    "     'param_grid': {'criterion': ['gini', 'entropy']}},\n",
    "    {'model': SVC(),\n",
    "     'param_grid': {'C': [0.01,0.1,1.0,10.0,100.0]}},\n",
    "    {'model': LinearSVC(),\n",
    "     'param_grid': {'C': [0.01,0.1,1.0,10.0,100.0], 'penalty': ['l1', 'l2']}}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Dictionary and compile all scores into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.782, test=0.762), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.791, test=0.832), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.796, test=0.817), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.809, test=0.768), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.807, test=0.796), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet ......................................\n",
      "[CV]  C=0.01, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.789, test=0.804), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.814, test=0.789), total=   0.0s\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.814, test=0.732), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.01, penalty=none ............................................\n",
      "[CV]  C=0.01, penalty=none, score=(train=0.793, test=0.796), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.819, test=0.797), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.807, test=0.825), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.805, test=0.746), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.819, test=0.754), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.798, test=0.817), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet .......................................\n",
      "[CV]  C=0.1, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.789, test=0.804), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.814, test=0.789), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.814, test=0.732), total=   0.0s\n",
      "[CV] C=0.1, penalty=none .............................................\n",
      "[CV]  C=0.1, penalty=none, score=(train=0.793, test=0.796), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.803, test=0.790), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.800, test=0.811), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.805, test=0.775), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.816, test=0.732), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.784, test=0.796), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=elasticnet .......................................\n",
      "[CV]  C=1.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.789, test=0.804), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.814, test=0.789), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.814, test=0.732), total=   0.0s\n",
      "[CV] C=1.0, penalty=none .............................................\n",
      "[CV]  C=1.0, penalty=none, score=(train=0.793, test=0.796), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.793, test=0.811), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.814, test=0.789), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.812, test=0.732), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.788, test=0.796), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=elasticnet ......................................\n",
      "[CV]  C=10.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.789, test=0.804), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.814, test=0.789), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.814, test=0.732), total=   0.0s\n",
      "[CV] C=10.0, penalty=none ............................................\n",
      "[CV]  C=10.0, penalty=none, score=(train=0.793, test=0.796), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100.0, penalty=l2, score=(train=0.789, test=0.804), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.814, test=0.789), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.814, test=0.732), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.793, test=0.796), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=elasticnet .....................................\n",
      "[CV]  C=100.0, penalty=elasticnet, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.801, test=0.790), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.789, test=0.804), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.814, test=0.789), total=   0.0s\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.814, test=0.732), total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=100.0, penalty=none ...........................................\n",
      "[CV]  C=100.0, penalty=none, score=(train=0.793, test=0.796), total=   0.0s\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.863, test=0.769), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... n_neighbors=1, score=(train=0.830, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.688, test=0.634), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.854, test=0.768), total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ... n_neighbors=1, score=(train=0.816, test=0.754), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.833, test=0.776), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.812, test=0.811), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.839, test=0.803), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.837, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ... n_neighbors=2, score=(train=0.812, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.845, test=0.797), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.838, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.849, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.851, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ... n_neighbors=3, score=(train=0.826, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.831, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.830, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.826, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.833, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=4 ...................................................\n",
      "[CV] ... n_neighbors=4, score=(train=0.812, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.830, test=0.839), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.837, test=0.804), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.826, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.828, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ... n_neighbors=5, score=(train=0.818, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.810, test=0.811), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.828, test=0.811), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.821, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.833, test=0.782), total=   0.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] ... n_neighbors=6, score=(train=0.814, test=0.746), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.835, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.835, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.828, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.821, test=0.796), total=   0.0s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ... n_neighbors=7, score=(train=0.809, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.807, test=0.783), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.828, test=0.818), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.825, test=0.789), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.833, test=0.775), total=   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] ... n_neighbors=8, score=(train=0.816, test=0.782), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.814, test=0.797), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.819, test=0.811), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.826, test=0.761), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.826, test=0.768), total=   0.0s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ... n_neighbors=9, score=(train=0.821, test=0.803), total=   0.0s\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.749, test=0.706), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.729, test=0.762), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.732, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.742, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.0 ...............................................\n",
      "[CV]  var_smoothing=1.0, score=(train=0.740, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.756, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.743, test=0.769), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.744, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.754, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.8111308307896871 ................................\n",
      "[CV]  var_smoothing=0.8111308307896871, score=(train=0.749, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.756, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.745, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.751, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.758, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.657933224657568 .................................\n",
      "[CV]  var_smoothing=0.657933224657568, score=(train=0.753, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.754, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.756, test=0.783), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.754, test=0.768), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.756, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.533669923120631 .................................\n",
      "[CV]  var_smoothing=0.533669923120631, score=(train=0.744, test=0.704), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.756, test=0.734), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.740, test=0.783), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.749, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.781, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.43287612810830584 ...............................\n",
      "[CV]  var_smoothing=0.43287612810830584, score=(train=0.744, test=0.704), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.750, test=0.699), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.759, test=0.818), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.747, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.779, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.3511191734215131 ................................\n",
      "[CV]  var_smoothing=0.3511191734215131, score=(train=0.749, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.775, test=0.734), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.789, test=0.839), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.795, test=0.789), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.798, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.2848035868435802 ................................\n",
      "[CV]  var_smoothing=0.2848035868435802, score=(train=0.784, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.768, test=0.734), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.779, test=0.825), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.791, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.788, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.23101297000831597 ...............................\n",
      "[CV]  var_smoothing=0.23101297000831597, score=(train=0.782, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.777, test=0.762), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.768, test=0.811), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.781, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.788, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.1873817422860384 ................................\n",
      "[CV]  var_smoothing=0.1873817422860384, score=(train=0.784, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.777, test=0.762), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.766, test=0.783), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.781, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.779, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.15199110829529336 ...............................\n",
      "[CV]  var_smoothing=0.15199110829529336, score=(train=0.777, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.773, test=0.762), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.766, test=0.783), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.775, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.777, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.12328467394420659 ...............................\n",
      "[CV]  var_smoothing=0.12328467394420659, score=(train=0.774, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.775, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.764, test=0.783), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.770, test=0.754), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.777, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.1 ...............................................\n",
      "[CV]  var_smoothing=0.1, score=(train=0.772, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.768, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.770, test=0.761), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.779, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.08111308307896872 ...............................\n",
      "[CV]  var_smoothing=0.08111308307896872, score=(train=0.763, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.772, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.767, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.768, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0657933224657568 ................................\n",
      "[CV]  var_smoothing=0.0657933224657568, score=(train=0.767, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.763, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.773, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.772, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.768, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.0533669923120631 ................................\n",
      "[CV]  var_smoothing=0.0533669923120631, score=(train=0.761, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.763, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.773, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.777, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.772, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.04328761281083057 ...............................\n",
      "[CV]  var_smoothing=0.04328761281083057, score=(train=0.761, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.763, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.772, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.772, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.03511191734215131 ...............................\n",
      "[CV]  var_smoothing=0.03511191734215131, score=(train=0.761, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.750, test=0.755), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.774, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.02848035868435802 ...............................\n",
      "[CV]  var_smoothing=0.02848035868435802, score=(train=0.768, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.749, test=0.755), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.774, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.758, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.02310129700083159 ...............................\n",
      "[CV]  var_smoothing=0.02310129700083159, score=(train=0.768, test=0.725), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.749, test=0.755), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.749, test=0.746), total=   0.0s\n",
      "[CV] var_smoothing=0.01873817422860384 ...............................\n",
      "[CV]  var_smoothing=0.01873817422860384, score=(train=0.754, test=0.697), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.759, test=0.755), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.775, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.746, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.01519911082952933 ...............................\n",
      "[CV]  var_smoothing=0.01519911082952933, score=(train=0.756, test=0.697), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.763, test=0.748), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.775, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.746, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.012328467394420659 ..............................\n",
      "[CV]  var_smoothing=0.012328467394420659, score=(train=0.756, test=0.697), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.763, test=0.748), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.775, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.740, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.01 ..............................................\n",
      "[CV]  var_smoothing=0.01, score=(train=0.735, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.763, test=0.748), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.773, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.775, test=0.739), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.740, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.008111308307896872 ..............................\n",
      "[CV]  var_smoothing=0.008111308307896872, score=(train=0.735, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.745, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.754, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.749, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.006579332246575682 ..............................\n",
      "[CV]  var_smoothing=0.006579332246575682, score=(train=0.735, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.743, test=0.727), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.768, test=0.776), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.754, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.749, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.005336699231206307 ..............................\n",
      "[CV]  var_smoothing=0.005336699231206307, score=(train=0.737, test=0.676), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.738, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.764, test=0.797), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.754, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.721, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.004328761281083057 ..............................\n",
      "[CV]  var_smoothing=0.004328761281083057, score=(train=0.737, test=0.676), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.738, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.764, test=0.797), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.754, test=0.711), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.721, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.003511191734215131 ..............................\n",
      "[CV]  var_smoothing=0.003511191734215131, score=(train=0.737, test=0.676), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.738, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.764, test=0.797), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.721, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.002848035868435802 ..............................\n",
      "[CV]  var_smoothing=0.002848035868435802, score=(train=0.737, test=0.676), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.740, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.764, test=0.797), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.721, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0023101297000831605 .............................\n",
      "[CV]  var_smoothing=0.0023101297000831605, score=(train=0.737, test=0.676), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.740, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.764, test=0.797), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.719, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.001873817422860383 ..............................\n",
      "[CV]  var_smoothing=0.001873817422860383, score=(train=0.737, test=0.676), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.764, test=0.797), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0015199110829529332 .............................\n",
      "[CV]  var_smoothing=0.0015199110829529332, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0012328467394420659 .............................\n",
      "[CV]  var_smoothing=0.0012328467394420659, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.001 .............................................\n",
      "[CV]  var_smoothing=0.001, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0008111308307896872 .............................\n",
      "[CV]  var_smoothing=0.0008111308307896872, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0006579332246575676 .............................\n",
      "[CV]  var_smoothing=0.0006579332246575676, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0005336699231206307 .............................\n",
      "[CV]  var_smoothing=0.0005336699231206307, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0004328761281083057 .............................\n",
      "[CV]  var_smoothing=0.0004328761281083057, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0003511191734215131 .............................\n",
      "[CV]  var_smoothing=0.0003511191734215131, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0002848035868435802 .............................\n",
      "[CV]  var_smoothing=0.0002848035868435802, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0002310129700083158 .............................\n",
      "[CV]  var_smoothing=0.0002310129700083158, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0001873817422860383 .............................\n",
      "[CV]  var_smoothing=0.0001873817422860383, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.742, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0001519911082952933 .............................\n",
      "[CV]  var_smoothing=0.0001519911082952933, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0001232846739442066 .............................\n",
      "[CV]  var_smoothing=0.0001232846739442066, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=0.0001 ............................................\n",
      "[CV]  var_smoothing=0.0001, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-05 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-05 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=5.3366992312063123e-05 ............................\n",
      "[CV]  var_smoothing=5.3366992312063123e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083062e-05 .............................\n",
      "[CV]  var_smoothing=4.328761281083062e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=3.511191734215127e-05 .............................\n",
      "[CV]  var_smoothing=3.511191734215127e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-05 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-05 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-05 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.5199110829529332e-05 ............................\n",
      "[CV]  var_smoothing=1.5199110829529332e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420658e-05 ............................\n",
      "[CV]  var_smoothing=1.2328467394420658e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1e-05 .............................................\n",
      "[CV]  var_smoothing=1e-05, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-06 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575683e-06 .............................\n",
      "[CV]  var_smoothing=6.579332246575683e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-06 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083053e-06 .............................\n",
      "[CV]  var_smoothing=4.328761281083053e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151275e-06 ............................\n",
      "[CV]  var_smoothing=3.5111917342151275e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-06 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-06 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-06 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-06 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-06 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1e-06 .............................................\n",
      "[CV]  var_smoothing=1e-06, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896872e-07 .............................\n",
      "[CV]  var_smoothing=8.111308307896872e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-07 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206313e-07 .............................\n",
      "[CV]  var_smoothing=5.336699231206313e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-07 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-07 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-07 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-07 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=2.310129700083158e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-07 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-07 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-07 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1e-07 .............................................\n",
      "[CV]  var_smoothing=1e-07, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896873e-08 .............................\n",
      "[CV]  var_smoothing=8.111308307896873e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-08 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-08 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=4.3287612810830526e-08 ............................\n",
      "[CV]  var_smoothing=4.3287612810830526e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151277e-08 ............................\n",
      "[CV]  var_smoothing=3.5111917342151277e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435799e-08 .............................\n",
      "[CV]  var_smoothing=2.848035868435799e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-08 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860383e-08 .............................\n",
      "[CV]  var_smoothing=1.873817422860383e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-08 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.232846739442066e-08 .............................\n",
      "[CV]  var_smoothing=1.232846739442066e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  var_smoothing=1e-08, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1e-08 .............................................\n",
      "[CV]  var_smoothing=1e-08, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=8.111308307896856e-09 .............................\n",
      "[CV]  var_smoothing=8.111308307896856e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=6.579332246575682e-09 .............................\n",
      "[CV]  var_smoothing=6.579332246575682e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=5.336699231206302e-09 .............................\n",
      "[CV]  var_smoothing=5.336699231206302e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=4.328761281083061e-09 .............................\n",
      "[CV]  var_smoothing=4.328761281083061e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=3.5111917342151273e-09 ............................\n",
      "[CV]  var_smoothing=3.5111917342151273e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.848035868435805e-09 .............................\n",
      "[CV]  var_smoothing=2.848035868435805e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=2.310129700083158e-09 .............................\n",
      "[CV]  var_smoothing=2.310129700083158e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.873817422860387e-09 .............................\n",
      "[CV]  var_smoothing=1.873817422860387e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.519911082952933e-09 .............................\n",
      "[CV]  var_smoothing=1.519911082952933e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1.2328467394420635e-09 ............................\n",
      "[CV]  var_smoothing=1.2328467394420635e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.743, test=0.720), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.764, test=0.790), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.733, test=0.683), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.716, test=0.732), total=   0.0s\n",
      "[CV] var_smoothing=1e-09 .............................................\n",
      "[CV]  var_smoothing=1e-09, score=(train=0.728, test=0.669), total=   0.0s\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.875, test=0.811), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.872, test=0.825), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.875, test=0.817), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.882, test=0.768), total=   0.0s\n",
      "[CV] criterion=gini ..................................................\n",
      "[CV] .. criterion=gini, score=(train=0.865, test=0.838), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.875, test=0.818), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.872, test=0.818), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.875, test=0.817), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, score=(train=0.882, test=0.768), total=   0.0s\n",
      "[CV] criterion=entropy ...............................................\n",
      "[CV]  criterion=entropy, score=(train=0.865, test=0.845), total=   0.0s\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.624, test=0.622), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.624, test=0.622), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.623, test=0.627), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.623, test=0.627), total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.625, test=0.620), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.786, test=0.797), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.794, test=0.811), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.796, test=0.754), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.796, test=0.754), total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.800, test=0.824), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.833, test=0.832), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.831, test=0.825), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.826, test=0.803), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.844, test=0.796), total=   0.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.830, test=0.845), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.863, test=0.818), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.856, test=0.811), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.863, test=0.831), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.870, test=0.775), total=   0.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.849, test=0.852), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.875, test=0.797), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.872, test=0.818), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.875, test=0.817), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.882, test=0.775), total=   0.0s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.865, test=0.852), total=   0.0s\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] .. C=0.01, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.801, test=0.804), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.794, test=0.797), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.798, test=0.754), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.811, test=0.761), total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV]  C=0.01, penalty=l2, score=(train=0.795, test=0.831), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ... C=0.1, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.803, test=0.811), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, penalty=l2, score=(train=0.800, test=0.804), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.804, test=0.746), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.818, test=0.739), total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV]  C=0.1, penalty=l2, score=(train=0.798, test=0.817), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ... C=1.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.803, test=0.811), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.791, test=0.811), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.802, test=0.754), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.818, test=0.732), total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV]  C=1.0, penalty=l2, score=(train=0.789, test=0.796), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l1 ..............................................\n",
      "[CV] .. C=10.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10.0, penalty=l2, score=(train=0.803, test=0.811), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.793, test=0.811), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.802, test=0.754), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.819, test=0.732), total=   0.0s\n",
      "[CV] C=10.0, penalty=l2 ..............................................\n",
      "[CV]  C=10.0, penalty=l2, score=(train=0.798, test=0.810), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l1 .............................................\n",
      "[CV] . C=100.0, penalty=l1, score=(train=nan, test=nan), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.745, test=0.692), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.705, test=0.727), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.802, test=0.725), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.749, test=0.739), total=   0.0s\n",
      "[CV] C=100.0, penalty=l2 .............................................\n",
      "[CV]  C=100.0, penalty=l2, score=(train=0.702, test=0.690), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i in Dict:\n",
    "    # Fit Training Data to model selected\n",
    "    model = i['model']\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict Train Data\n",
    "    y_predict_train_data = model.predict(X_train)\n",
    "    x_train_accuracy_score = accuracy_score(y_train, y_predict_train_data)\n",
    "    x_train_auc_score = roc_auc_score(y_train, y_predict_train_data)\n",
    "\n",
    "    # Predict Test Data\n",
    "    y_predict_test_data = model.predict(X_test)\n",
    "    x_test_accuracy_score = accuracy_score(y_test, y_predict_test_data)\n",
    "    x_test_auc_score = roc_auc_score(y_test, y_predict_test_data)\n",
    "\n",
    "    # Calculate Confusion_Matrix\n",
    "    cm = confusion_matrix(y_test, y_predict_test_data)\n",
    "\n",
    "    # Perform Hyperparameter Tuning & Cross Validation\n",
    "    grid_search = GridSearchCV(model, param_grid=i['param_grid'], cv=5, verbose=3, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    rows.append([model, \n",
    "                 \"{:.2f}%\".format(x_train_accuracy_score*100), \n",
    "                 \"{:.2f}%\".format(x_test_accuracy_score*100), \n",
    "                 \"{:.2f}\".format(x_train_auc_score), \n",
    "                 \"{:.2f}\".format(x_test_auc_score), \n",
    "                 cm,\n",
    "                 grid_search.best_params_,\n",
    "                 \"{:.2f}%\".format(grid_search.best_score_*100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Summary Table Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Algorithm accuracy_score(train) accuracy_score(test)  \\\n",
      "0      LogisticRegression()                80.62%               79.89%   \n",
      "1    KNeighborsClassifier()                81.74%               77.65%   \n",
      "2              GaussianNB()                73.03%               72.63%   \n",
      "3  DecisionTreeClassifier()                86.94%               82.68%   \n",
      "4                     SVC()                83.29%               80.45%   \n",
      "5               LinearSVC()                80.76%               79.89%   \n",
      "\n",
      "  roc_auc_score(train) roc_auc_score(test)      Confusion Matrix  \\\n",
      "0                 0.79                0.79  [[88, 17], [19, 55]]   \n",
      "1                 0.79                0.76  [[91, 14], [26, 48]]   \n",
      "2                 0.69                0.70  [[88, 17], [32, 42]]   \n",
      "3                 0.84                0.81  [[94, 11], [20, 54]]   \n",
      "4                 0.81                0.79  [[91, 14], [21, 53]]   \n",
      "5                 0.78                0.79  [[90, 15], [21, 53]]   \n",
      "\n",
      "                              Best Param Best Score  \n",
      "0           {'C': 0.01, 'penalty': 'l2'}     79.49%  \n",
      "1                     {'n_neighbors': 7}     80.19%  \n",
      "2  {'var_smoothing': 0.2848035868435802}     77.10%  \n",
      "3               {'criterion': 'entropy'}     81.32%  \n",
      "4                             {'C': 1.0}     82.02%  \n",
      "5           {'C': 0.01, 'penalty': 'l2'}     78.93%  \n"
     ]
    }
   ],
   "source": [
    "summary_table = pd.DataFrame(rows, columns=[\"Algorithm\", \n",
    "                                            \"accuracy_score(train)\", \n",
    "                                            \"accuracy_score(test)\", \n",
    "                                            \"roc_auc_score(train)\", \n",
    "                                            \"roc_auc_score(test)\", \n",
    "                                            \"Confusion Matrix\",\n",
    "                                            \"Best Param\",\n",
    "                                            \"Best Score\"])\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Competition\n",
    "=================\n",
    "From the Best Score, select the Best Model (SVC) to perform the Titanic prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_kaggle = pd.read_csv('data/test.csv', sep=',')\n",
    "passengerId = df_kaggle['PassengerId']\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_kaggle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex_female  Sex_male  Cabin_No  Cabin_Yes  Embarked_C  Embarked_Q  \\\n",
      "0       3           0         1         1          0           0           1   \n",
      "1       3           1         0         1          0           0           0   \n",
      "2       2           0         1         1          0           0           1   \n",
      "3       3           0         1         1          0           0           0   \n",
      "4       3           1         0         1          0           0           0   \n",
      "\n",
      "   Embarked_S  hasFamilyAboard_No  hasFamilyAboard_Yes  ...  Fare_Group_2  \\\n",
      "0           0                   1                    0  ...             0   \n",
      "1           1                   1                    0  ...             0   \n",
      "2           0                   1                    0  ...             0   \n",
      "3           1                   1                    0  ...             0   \n",
      "4           1                   0                    1  ...             1   \n",
      "\n",
      "   Fare_Group_3  Fare_Group_4  Fare_Group_5  Fare_Group_6  Fare_Group_7  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             0             0             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             0             0             0             0   \n",
      "4             0             0             0             0             0   \n",
      "\n",
      "   Fare_Group_8  Age_Group_Children  Age_Group_Adult  Age_Group_Elderly  \n",
      "0             0                   0                1                  0  \n",
      "1             0                   0                1                  0  \n",
      "2             0                   0                0                  1  \n",
      "3             0                   0                1                  0  \n",
      "4             0                   0                1                  0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(418, 21)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection\n",
    "df_kaggle = df_kaggle.drop(['PassengerId', 'Name', 'Ticket'], 1)\n",
    "\n",
    "# SibSp & Parch\n",
    "df_kaggle['hasFamilyAboard'] = np.where((df_kaggle['SibSp'] > 0) & (df_kaggle['Parch'] > 0), 'Yes', 'No')\n",
    "df_kaggle = df_kaggle.drop(['SibSp', 'Parch'], 1)\n",
    "\n",
    "# Fare\n",
    "df_kaggle['Fare'].fillna(df_kaggle['Fare'].mean(), inplace=True)\n",
    "fare_bins=[0,10,20,40,60,80,100,200,600]\n",
    "fare_labels=[1,2,3,4,5,6,7,8]\n",
    "df_kaggle['Fare_Group'] = pd.cut(df_kaggle['Fare'], bins=fare_bins, labels=fare_labels, right=False)\n",
    "df_kaggle = df_kaggle.drop('Fare', 1)\n",
    "\n",
    "# Cabin\n",
    "df_kaggle['Cabin'].fillna('No', inplace=True)\n",
    "df_kaggle['Cabin'].replace(regex=r'^((?!No).)*$',value='Yes',inplace=True)\n",
    "\n",
    "# Age\n",
    "df_kaggle['Age'].fillna(df_kaggle['Age'].mean(), inplace=True)\n",
    "age_bins=[0,13,60,120]\n",
    "age_labels=['Children','Adult','Elderly']\n",
    "df_kaggle['Age_Group'] = pd.cut(df_kaggle['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "df_kaggle = df_kaggle.drop('Age', 1)\n",
    "\n",
    "# Encoding\n",
    "df_kaggle = pd.get_dummies(df_kaggle)\n",
    "print(df_kaggle.head())\n",
    "df_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 83.29%\n",
      "Test Data Score: 80.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1.0)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "training_score = svc.score(X_train, y_train)\n",
    "print(\"Training Data Score: {:.2f}%\".format(training_score*100))\n",
    "\n",
    "test_score = svc.score(X_test, y_test)\n",
    "print(\"Test Data Score: {:.2f}%\".format(test_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Titanic Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_kaggle = df_kaggle\n",
    "kaggle_predict = svc.predict(X_kaggle)\n",
    "print(kaggle_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'PassengerId': passengerId, 'Survived': kaggle_predict}, columns=['PassengerId', 'Survived'])\n",
    "result.to_csv('submission.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission Result\n",
    "The submission result is **77.03% (0.77033)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image\\kaggle_submission_result.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References / Appendixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://www.kaggle.com/c/titanic/data\n",
    "2. https://www.kaggle.com/c/titanic/submit\n",
    "3. https://scikit-learn.org/stable/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
